{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Feature Selection\n",
    "from copy import deepcopy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['0_CIC-IDS-2017', '1_UNSW-NB15', '2_NF-UNSW-NB15-v2', '3_CSE-CIC-IDS2018', '4_NSL-KDD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones Utilitarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def execute_feature_selection(dataset):\n",
    "#     warnings.filterwarnings(\"ignore\")\n",
    "dataset = datasets[4]\n",
    "\n",
    "def load_dataset(dataset):\n",
    "    folder = f'./small_datasets_clean/{dataset}'\n",
    "    X = pd.read_csv(f'{folder}/X.csv')\n",
    "    y = pd.read_csv(f'{folder}/Y.csv')\n",
    "    return X,y\n",
    "\n",
    "def print_to_results(msg, type = 'a'):\n",
    "    print(msg)\n",
    "    folder = 'results_feature_selection'\n",
    "    file = open(f'./{folder}/{dataset}.txt', type)\n",
    "    file.write(f'{msg}\\n\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccion de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccion de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(model, params):\n",
    "    grid = fit_grid(model, params)\n",
    "    best_selector = grid.best_estimator_['select']\n",
    "    selected_features = X_train.columns[best_selector.get_support()]\n",
    "    save_results(grid, selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_grid(model, params):\n",
    "    grid = GridSearchCV(model, params, error_score=0)\n",
    "    grid.fit(X_train, y_train)    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(grid, selected_features = None):\n",
    "    train_accuracy = round(grid.best_score_, 6)\n",
    "    fit_time = round(grid.cv_results_['mean_fit_time'].mean(), 3)\n",
    "    score_time = round(grid.cv_results_['mean_score_time'].mean(), 3)\n",
    "    test_accuracy = round(grid.best_estimator_.score(X_test, y_test), 6)\n",
    "\n",
    "    result =   (f\"Best model: {grid.best_estimator_}\\n\"\n",
    "                f\"Train Accuracy: {train_accuracy}\\n\"\n",
    "                f\"Average Time to Fit (s): {fit_time}\\n\"\n",
    "                f\"Average Time to Score (s): {score_time}\\n\"\n",
    "                f\"Test Accuracy: {test_accuracy}\")\n",
    "                \n",
    "    if(selected_features is not None):\n",
    "        result =   (f\"{result}\"\n",
    "                    f\"\\nNumber of features: {len(selected_features)}\\n\"\n",
    "                    f\"{selected_features}\")\n",
    "                \n",
    "    print_to_results(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Feature Selection at 2022-10-13 13:42:01.969371\n",
      "Dataset: 4_NSL-KDD\n",
      "X shape: (1999, 41)\n",
      "y shape: (1999, 1)\n",
      "y proportions: \n",
      "class\n",
      "0        0.51926\n",
      "1        0.48074\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_to_results(f'Starting Feature Selection at {datetime.now()}', 'w')\n",
    "X, y = load_dataset(dataset)\n",
    "\n",
    "header = (f'Dataset: {dataset}\\n'\n",
    "          f'X shape: {X.shape}\\n'  \n",
    "          f'y shape: {y.shape}\\n' \n",
    "          f'y proportions: \\n{y.value_counts(normalize=True)}\\n')\n",
    "\n",
    "print_to_results(header)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminar columnas constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_filter = VarianceThreshold(threshold=0)\n",
    "Xcols = X.columns\n",
    "X = variance_filter.fit_transform(X)\n",
    "Xcols = Xcols[variance_filter.get_support()]\n",
    "X = pd.DataFrame(X, columns=Xcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base models\n"
     ]
    }
   ],
   "source": [
    "print_to_results(\"Base models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "tree = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "lr_params = {'classifier__C':[0.1, 1, 10]}\n",
    "knn_params = {'classifier__n_neighbors': [1, 3, 5]}\n",
    "tree_params = {'classifier__max_depth': [11, 13, 15]}\n",
    "forest_params = {'classifier__n_estimators': [50, 100], 'classifier__max_depth': [1, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('classifier', LogisticRegression(C=10))])\n",
      "Train Accuracy: 0.955969\n",
      "Average Time to Fit (s): 0.015\n",
      "Average Time to Score (s): 0.001\n",
      "Test Accuracy: 0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = Pipeline([('classifier', lr)])\n",
    "grid_lr = fit_grid(pipe_lr, lr_params)\n",
    "save_results(grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('classifier', KNeighborsClassifier(n_neighbors=1))])\n",
      "Train Accuracy: 0.973309\n",
      "Average Time to Fit (s): 0.002\n",
      "Average Time to Score (s): 0.015\n",
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "pipe_knn = Pipeline([('classifier', knn)])\n",
    "grid_knn = fit_grid(pipe_knn, knn_params)\n",
    "save_results(grid_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('classifier', DecisionTreeClassifier(max_depth=11))])\n",
      "Train Accuracy: 0.978653\n",
      "Average Time to Fit (s): 0.005\n",
      "Average Time to Score (s): 0.001\n",
      "Test Accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "pipe_tree = Pipeline([('classifier', tree)])\n",
    "grid_tree = fit_grid(pipe_tree, tree_params)\n",
    "save_results(grid_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('classifier',\n",
      "                 RandomForestClassifier(max_depth=3, n_estimators=50))])\n",
      "Train Accuracy: 0.964647\n",
      "Average Time to Fit (s): 0.068\n",
      "Average Time to Score (s): 0.006\n",
      "Test Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "pipe_forest = Pipeline([('classifier', forest)])\n",
    "grid_forest = fit_grid(pipe_forest, forest_params)\n",
    "save_results(grid_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eleccion del mejor modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best base model: DecisionTreeClassifier()\n"
     ]
    }
   ],
   "source": [
    "classifiers = [lr, knn, tree, forest]\n",
    "params = [lr_params, knn_params, tree_params, forest_params]\n",
    "best_scores = [grid_lr.best_score_, grid_knn.best_score_, grid_tree.best_score_, grid_forest.best_score_]\n",
    "\n",
    "\n",
    "best_index = np.argmax(best_scores)\n",
    "classifier = classifiers[best_index]\n",
    "classifier_params = params[best_index]\n",
    "print_to_results(f\"Best base model: {classifier}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filters\n"
     ]
    }
   ],
   "source": [
    "print_to_results(\"Filters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(X,y):\n",
    "    y = y.reshape((y.size,-1))\n",
    "    np_data = np.concatenate([X,y], axis=1)\n",
    "    pd_data = pd.DataFrame(np_data)    \n",
    "    corr = pd_data.corr().abs().iloc[-1]\n",
    "    corr = corr[:-1]\n",
    "    return np.array(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlacion\n",
      "Best model: Pipeline(steps=[('select',\n",
      "                 SelectKBest(k=20,\n",
      "                             score_func=<function correlation at 0x00000206429B1700>)),\n",
      "                ('classifier', DecisionTreeClassifier(max_depth=11))])\n",
      "Train Accuracy: 0.975984\n",
      "Average Time to Fit (s): 0.007\n",
      "Average Time to Score (s): 0.001\n",
      "Test Accuracy: 0.97\n",
      "Number of features: 20\n",
      "Index(['protocol_type', 'service', 'flag', 'dst_bytes', 'logged_in', 'count',\n",
      "       'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
      "       'same_srv_rate', 'diff_srv_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print_to_results(\"Correlacion\")\n",
    "\n",
    "corr_pipe = Pipeline([('select', SelectKBest(correlation)), \n",
    "                      ('classifier', classifier)])\n",
    "\n",
    "corr_pipe_params = deepcopy(classifier_params)\n",
    "\n",
    "corr_pipe_params.update({'select__k':[10,15,20]})\n",
    "\n",
    "select_features(corr_pipe, corr_pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [11] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [12] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [11] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [12] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [11] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [12] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [11] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [12] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [11] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [12] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [11] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [12] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [11] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [12] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [11] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [12] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('select', SelectKBest(k=20)),\n",
      "                ('classifier', DecisionTreeClassifier(max_depth=13))])\n",
      "Train Accuracy: 0.976653\n",
      "Average Time to Fit (s): 0.004\n",
      "Average Time to Score (s): 0.001\n",
      "Test Accuracy: 0.976\n",
      "Number of features: 20\n",
      "Index(['protocol_type', 'service', 'flag', 'dst_bytes', 'logged_in', 'count',\n",
      "       'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
      "       'same_srv_rate', 'diff_srv_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [11] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [12] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Alejandro Duque\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "print_to_results(\"P-value\")\n",
    "\n",
    "p_value_pipe = Pipeline([('select', SelectKBest(f_classif)), \n",
    "                         ('classifier', classifier)])\n",
    "\n",
    "p_value_pipe_params = deepcopy(classifier_params)\n",
    "\n",
    "p_value_pipe_params.update({'select__k':[10,15,20]})\n",
    "\n",
    "select_features(p_value_pipe, p_value_pipe_params)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrappers\n"
     ]
    }
   ],
   "source": [
    "print_to_results(\"Wrappers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Best model: Pipeline(steps=[('select',\n",
      "                 SelectFromModel(estimator=DecisionTreeClassifier(),\n",
      "                                 max_features=20)),\n",
      "                ('classifier', DecisionTreeClassifier(max_depth=15))])\n",
      "Train Accuracy: 0.978651\n",
      "Average Time to Fit (s): 0.005\n",
      "Average Time to Score (s): 0.001\n",
      "Test Accuracy: 0.976\n",
      "Number of features: 5\n",
      "Index(['service', 'dst_bytes', 'count', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_serror_rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print_to_results(\"Decision Tree\")\n",
    "\n",
    "tree_pipe = Pipeline([('select', SelectFromModel(DecisionTreeClassifier())), \n",
    "                      ('classifier', classifier)])\n",
    "\n",
    "tree_pipe_params = deepcopy(classifier_params)\n",
    "\n",
    "tree_pipe_params.update({\n",
    "              'select__max_features': [20],\n",
    "              'select__estimator__max_depth': [None, 1, 3, 5]\n",
    "              })\n",
    "\n",
    "select_features(tree_pipe, tree_pipe_params)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Best model: Pipeline(steps=[('select',\n",
      "                 SelectFromModel(estimator=LogisticRegression(),\n",
      "                                 max_features=20)),\n",
      "                ('classifier', DecisionTreeClassifier(max_depth=11))])\n",
      "Train Accuracy: 0.965975\n",
      "Average Time to Fit (s): 0.015\n",
      "Average Time to Score (s): 0.001\n",
      "Test Accuracy: 0.968\n",
      "Number of features: 15\n",
      "Index(['protocol_type', 'wrong_fragment', 'hot', 'is_guest_login', 'count',\n",
      "       'serror_rate', 'srv_serror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
      "       'dst_host_srv_count', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_srv_rerror_rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print_to_results(\"Logistic Regression\")\n",
    "\n",
    "logistic_pipe = Pipeline([('select', SelectFromModel(LogisticRegression())), \n",
    "                          ('classifier', classifier)])\n",
    "\n",
    "logistic_pipe_params = deepcopy(classifier_params)\n",
    "\n",
    "logistic_pipe_params.update({\n",
    "              'select__max_features': [20]\n",
    "              })\n",
    "              \n",
    "select_features(logistic_pipe, logistic_pipe_params) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Best model: Pipeline(steps=[('select',\n",
      "                 SelectFromModel(estimator=LinearSVC(), max_features=20)),\n",
      "                ('classifier', DecisionTreeClassifier(max_depth=11))])\n",
      "Train Accuracy: 0.972651\n",
      "Average Time to Fit (s): 0.007\n",
      "Average Time to Score (s): 0.001\n",
      "Test Accuracy: 0.972\n",
      "Number of features: 20\n",
      "Index(['protocol_type', 'flag', 'wrong_fragment', 'hot', 'num_compromised',\n",
      "       'num_root', 'num_access_files', 'is_guest_login', 'count',\n",
      "       'srv_serror_rate', 'same_srv_rate', 'diff_srv_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_rerror_rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print_to_results(\"SVC\")\n",
    "\n",
    "svc_pipe = Pipeline([('select', SelectFromModel(LinearSVC())), \n",
    "                     ('classifier', classifier)])\n",
    "\n",
    "svc_pipe_params = deepcopy(classifier_params)\n",
    "\n",
    "svc_pipe_params.update({\n",
    "                'select__max_features': [20],\n",
    "                'select__estimator__dual': [True, False]\n",
    "              })\n",
    "\n",
    "select_features(svc_pipe, svc_pipe_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Feature Selection at 2022-10-13 13:42:06.490744\n"
     ]
    }
   ],
   "source": [
    "print_to_results(f'Finishing Feature Selection at {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     pool = multiprocessing.Pool(processes=5)\n",
    "#     pool.map(execute_feature_selection, datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5e66119bb7eb320cb615f17e3cf77c9243e0a63123323491c6aa600a9594b9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
